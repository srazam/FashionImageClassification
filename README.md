# Fashion Image Classification

Purpose of our Experiment:
Previous studies of image classification on fashion datasets focused on how accurate different items of clothing could be classified. However, many of these datasets involved isolated pieces of clothing rather than an item worn by any individual. This study aims to address this by analyzing classification patterns on dressed clothes in order to enhance understanding of fashion image classification and to test the limits of different models. This could be beneficial in a variety of ways, such as aiding in e-commerce with better recommendations or helping with mundane tasks such as categorizing clothes. Towards this, we analyzed a dataset that categorized dresses worn by people according to their patterns using three different convolutional neural networks (CNNs): VGG, AlexNet, and LeNet. After initial testing, we found that the results varied between different hardwares, leading to an exploration of issues with reproducibility and variance within deep learning models. With these new discoveries, the CNNs were modified to better assist with reproducibility and decrease variance. After these modifications and hyperparameter tuning, the VGG was the best model with a classification accuracy of 68%.
